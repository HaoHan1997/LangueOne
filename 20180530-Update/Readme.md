
## 20180530-Update

本次更新两样挖掘材料：

 - CoOccurrence_data_800.csv 
 - word_Understanding.csv


其中：

#### CoOccurrence_data_800.csv

是一个二元组缩略版，是跑了完整的今日头条关键词的结果，格式如下：

    Weight,Source,Target
    859,伊朗,特朗普
    681,叙利亚,以色列
    623,买房,房价
    613,俄罗斯,普京
    569,比特币,区块链
    563,叙利亚,伊朗

其中一部分内容，将其放入gephi中运行，可得：
![此处输入图片的描述][1]


#### word_Understanding.csv

是每个词对应的一些社交属性，可以作为一些标签，给不同的文本进行定义，格式如下：

    idset,word,len,chinese_class
    "[104, 106, 101, 110]",保利集团,4,"['财经,财经', '房产,房产', '文化,文化', '军事,军事']"
    "[101, 102]",马未都,2,"['文化,文化', '娱乐,娱乐']"
    "[108, 101]",中国科学技术馆,2,"['教育,教育', '文化,文化']"
    [101],林风眠,1,"['文化,文化']"
    [101],黄海归来步步云,1,"['文化,文化']"
    [101],秋山图,1,"['文化,文化']"


其中，不同编号代码不同的分属类型，

    sign = {100:'民生,故事',
    101:'文化,文化',
    102 :'娱乐,娱乐' ,
    103 :'体育,体育' ,
    104 :'财经,财经' ,
    106 :'房产,房产' ,
    107 :'汽车,汽车' ,
    108 :'教育,教育' , 
    109 :'科技,科技' ,
    110 :'军事,军事' ,
    112 :'旅游,旅游' ,
    113 :'国际,国际' ,
    114 :'证券,股票' ,
    115 :'农业,三农' ,
    116 :'电竞,游戏' }
    

该部分的后续应用可以以词粒度，给新文本打上不同的标签。
同时，基本上，如果一个词只有一个标签，譬如：`'黄海归来步步云'`那么一般分类`"['文化,文化']"`的质量都是挺高的。


  [1]: https://github.com/mattzheng/LangueOne/blob/master/20180530-Update/toutiao_gephi.png

